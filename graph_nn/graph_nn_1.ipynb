{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gen_l_eta', 'gen_lbar_eta', 'gen_l_phi', 'gen_lbar_phi', 'gen_l_pt', 'gen_lbar_pt', 'gen_l_mass', 'gen_lbar_mass', 'gen_nu_eta', 'gen_nubar_eta', 'gen_nu_phi', 'gen_nubar_phi', 'gen_nu_pt', 'gen_nubar_pt', 'gen_nu_mass', 'gen_nubar_mass', 'gen_b_eta', 'gen_bbar_eta', 'gen_b_phi', 'gen_bbar_phi', 'gen_b_pt', 'gen_bbar_pt', 'gen_b_mass', 'gen_bbar_mass', 'gen_top_eta', 'gen_tbar_eta', 'gen_top_phi', 'gen_tbar_phi', 'gen_top_pt', 'gen_tbar_pt', 'gen_top_mass', 'gen_tbar_mass', 'gen_wplus_eta', 'gen_wminus_eta', 'gen_wplus_phi', 'gen_wminus_phi', 'gen_wplus_pt', 'gen_wminus_pt', 'gen_wminus_mass', 'gen_wplus_mass', 'production_mode', 'eventWeight', '__index__']\n",
      "num qqbar = 52908\n",
      "4.0\n",
      "training torch.Size([84652, 10, 4])\n",
      "evaluating torch.Size([21163, 10, 4])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "######################################### Import statements ###########################################\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")   # this allows us to import from sibling directory\n",
    "\n",
    "from code_to_import.Graph_Dataset_Preprocessing import GraphProductionModeDataset\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F   # NOTE: I don't think this is used\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "import dgl\n",
    "import dgl.data\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Configure everything here\n",
    "\"\"\"\n",
    "\n",
    "class args():\n",
    "    channel = \"ee\"\n",
    "    cut = -1\n",
    "    version = -1\n",
    "    cut_version = -1\n",
    "    weight = \"true\"\n",
    "    drop = 0.2\n",
    "    input = \"allorentz_gen\"\n",
    "    includes_qg = \"false\"\n",
    "    dir_names = \"GNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN_Model4Layers_V1_ee_corrCut_-1_weights_true_drop_0.2_allorentz_gen_no_qg\n",
      "['gen_l_eta', 'gen_lbar_eta', 'gen_l_phi', 'gen_lbar_phi', 'gen_l_pt', 'gen_lbar_pt', 'gen_l_mass', 'gen_lbar_mass', 'gen_nu_eta', 'gen_nubar_eta', 'gen_nu_phi', 'gen_nubar_phi', 'gen_nu_pt', 'gen_nubar_pt', 'gen_nu_mass', 'gen_nubar_mass', 'gen_b_eta', 'gen_bbar_eta', 'gen_b_phi', 'gen_bbar_phi', 'gen_b_pt', 'gen_bbar_pt', 'gen_b_mass', 'gen_bbar_mass', 'gen_top_eta', 'gen_tbar_eta', 'gen_top_phi', 'gen_tbar_phi', 'gen_top_pt', 'gen_tbar_pt', 'gen_top_mass', 'gen_tbar_mass', 'gen_wplus_eta', 'gen_wminus_eta', 'gen_wplus_phi', 'gen_wminus_phi', 'gen_wplus_pt', 'gen_wminus_pt', 'gen_wminus_mass', 'gen_wplus_mass', 'production_mode', 'eventWeight', '__index__']\n",
      "num qqbar = 52908\n",
      "4.0\n",
      "training torch.Size([84652, 10, 4])\n",
      "evaluating torch.Size([21163, 10, 4])\n",
      "The model in this run is GNN_Model4Layers_V1_ee_corrCut_-1_weights_true_drop_0.2_allorentz_gen_no_qgbatch2000\n"
     ]
    }
   ],
   "source": [
    "######################## THIS CLASS INCLUDES ALL THE VARIABLES YOU WANT TO CONFIGURE #################################\n",
    "#######################################################################################################################\n",
    "\n",
    "class opt():   # Class used for optimizers in the future. Defines all variables and stuff needed.\n",
    "#     save_weights = True  # Tells whether to save weights... currently not used\n",
    "    \n",
    "    load_model = False  # set true if you want to load and continue training a previous model\n",
    "    \n",
    "    draw = True # set to false when running on slurm\n",
    "    \n",
    "    n_epochs = 40000   # an epoch is the number of times it works through the entire training set.\n",
    "                       # This sets the total number of epochs which will be run\n",
    "    \n",
    "    batch_size = 2000  # the training set is broken up into batches, \n",
    "                        # this sets the size of each batch\n",
    "    \n",
    "    # this is the number of outputs for the neural network\n",
    "    output_num = 3\n",
    "    if args.includes_qg != \"true\":\n",
    "        output_num = 2\n",
    "    \n",
    "    lr = 0.0001   # learning rate (how much to change based on error)\n",
    "    b1 = 0.9   # Used for Adam. Exponential decay rate for the first moment\n",
    "    b2 = 0.999   # Used for Adam. Exponential decay rate for the second moment estimates (gradient squared)\n",
    "        \n",
    "    correlation_cut = args.cut   # this is the correlation cut... If negative then no cut is applied\n",
    "    \n",
    "    drop = args.drop   # percentage of nodes which will be dropped each time\n",
    "    \n",
    "    weight_cmd = args.weight   # could also be \"false\" and \"no-neg\".\n",
    "                          # This determines whether weights and negative weights are used\n",
    "    \n",
    "    qg_cmd = (args.includes_qg == \"true\")   # this is a boolean which determines if qg is included (true) or excluded (false)\n",
    "    \n",
    "    # the root_path leads to the folder with the root files being used for data\n",
    "    root_path = \"/depot/cms/top/mcnama20/TopSpinCorr-Run2-Entanglement/CMSSW_10_2_22/src/TopAnalysis/Configuration/analysis/diLeptonic/three_files/Nominal\"\n",
    "    \n",
    "    # this is the data root file loaded into the dataloader\n",
    "    file = root_path + \"/\" + args.channel\n",
    "    if args.input == \"all\":\n",
    "        file += \"_modified_root_1.root\"   \n",
    "    elif args.input == \"lorentz\":\n",
    "        file += \"_modified_root_1_lorentzvectors.root\"\n",
    "    elif args.input == \"spinCorr\":\n",
    "        file +=\"_modified_root_1_spinCorr.root\"\n",
    "    elif args.input == \"lorentzdelta\":\n",
    "        file += \"_modified_root_1_lorentzvectorsdelta.root\"\n",
    "    #elif args.input == \"lorentzgen\":\n",
    "     #   file += \"_modified_root_1_lorentzvectorsdelta_gen.root\"\n",
    "    elif args.input == \"lorentz_mttbar\":\n",
    "        file += \"_modified_root_1_lorentzvectors_mttbar_mass.root\"\n",
    "    elif args.input == \"lorentz_delta2\":\n",
    "        file += \"__modified_root_1_lorentzvectorsdelta_version2.root\"\n",
    "    elif args.input == \"lorentzdelta_gen\":\n",
    "        file += \"_modified_root_1_lorentzvectorsdelta_gen.root\"\n",
    "    elif args.input == \"allorentz_gen\":\n",
    "        file += \"_modified_root_1_allorentz_gen.root\"\n",
    "    \n",
    "    # this is the model name. Change it when running a new model\n",
    "    model_name = \"GNN_Model4Layers_V1_\" + args.channel  + \"_weights_\" + weight_cmd\n",
    "    \n",
    "    # add version information if included\n",
    "    if args.version > 0:\n",
    "        model_name += str(args.version)\n",
    "                    \n",
    "    # add cut version to model name if included in args\n",
    "    if args.cut_version > 0:\n",
    "        model_name += \"cutV\" + str(args.cut_version)\n",
    "        \n",
    "    # add input type. Can be \"all\", \"lorentz\" and \"spinCorr\"\n",
    "    if args.input != \"all\":\n",
    "        model_name += \"_\" + args.input\n",
    "        \n",
    "    if not qg_cmd:\n",
    "        model_name += \"_no_qg\"\n",
    "    \n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    # load data object so we can access validation and training data    \n",
    "    if correlation_cut > 0:\n",
    "        data = GraphProductionModeDataset(file, correlation_cut=correlation_cut, cut_version=args.cut_version, include_qg = qg_cmd)\n",
    "    else:\n",
    "        data = GraphProductionModeDataset(file, include_qg = qg_cmd)\n",
    "        \n",
    "    model_name += \"batch\" + str(batch_size)\n",
    "        \n",
    "\n",
    "print(\"The model in this run is \" + opt.model_name)   # this will make slurm output easier to identify\n",
    "\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcnama20/.conda/envs/cent7/5.1.0-py36/GANS_7/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "###################### Now save training and validation sets for future analysis ###################################\n",
    "np.save(\"../data/GNN/train_val_datasets/training_dataset_\" + opt.model_name + \".npy\", opt.data.get_training_data())\n",
    "np.save(\"../data/GNN/train_val_datasets/validation_dataset_\" + opt.model_name + \".npy\", opt.data.get_eval_data())\n",
    "\n",
    "\n",
    "# In[29]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build up version\n",
    "        up_source = torch.tensor([6, 7, 8, 9, 2, 3, 4, 5])\n",
    "        up_range =  torch.tensor([3, 3, 4, 4, 0, 0, 1, 1])\n",
    "        \n",
    "        # build down version\n",
    "        down_source = torch.tensor([3, 3, 4, 4,  0, 0, 1, 1])\n",
    "        down_range = torch.tensor([6, 7, 8, 9, 2, 3, 4, 5])\n",
    "        \n",
    "        # similar type connection\n",
    "        sim_source = torch.tensor([6, 8, 7, 9, 2, 5, 3, 4, 0, 1])\n",
    "        sim_range = torch.tensor([8, 6, 9, 7, 5, 2, 4, 3, 1, 0])\n",
    "        \n",
    "        # same parent\n",
    "        child_source = torch.tensor([6, 7, 8, 9, 2, 3, 4, 5])\n",
    "        child_range = torch.tensor([7, 6, 9, 8, 3, 2, 5, 4])\n",
    "        \n",
    "        ############### for now I will include building up and both similar and same parent TODO: add parameter to determine\n",
    "        # this\n",
    "        source_ids = torch.cat((up_source, sim_source, child_source))\n",
    "        range_ids = torch.cat((up_range, sim_range, child_range))\n",
    "        graph = dgl.graph((source_ids, range_ids), num_nodes=10)\n",
    "        graph = dgl.add_self_loop(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=10, num_edges=36,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batched_graphs = graph\n",
    "\n",
    "for i in range(opt.batch_size - 1):\n",
    "    batched_graphs = dgl.batch([batched_graphs, graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batched_graphs = graph\n",
    "# for i in range(7):\n",
    "#     batched_graphs =dgl.batch([batched_graphs, batched_graphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=20000, num_edges=72000,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.8235e-01, 5.0006e-01, 1.0847e-01, 1.7250e+02],\n",
       "         [3.5852e-01, 7.7079e-01, 6.4876e-02, 1.7250e+02],\n",
       "         [3.5649e-01, 5.0298e-01, 1.0222e-01, 6.0678e-01],\n",
       "         [5.5413e-01, 4.9402e-01, 4.1555e-02, 4.8512e-01],\n",
       "         [3.3636e-01, 5.9707e-01, 4.1467e-02, 4.8534e-01],\n",
       "         [3.2623e-01, 8.7314e-01, 7.8170e-02, 6.5261e-01],\n",
       "         [3.6887e-01, 4.4456e-01, 6.7445e-02, 5.0103e-01],\n",
       "         [5.6041e-01, 8.3116e-01, 2.5951e-02, 6.1560e-01],\n",
       "         [3.4764e-01, 1.1157e-01, 2.4654e-02, 5.6265e-01],\n",
       "         [3.4763e-01, 6.0227e-01, 9.2736e-02, 5.4214e-01]]),\n",
       " 0.0,\n",
       " 0.8690045295014476)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "############################## Configure data loader depending on if there is a correlation cut ###########################\n",
    "if opt.correlation_cut > 0:\n",
    "    os.makedirs(\"../data/\" + args.dir_names + \"/\", exist_ok=True)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        opt.data,\n",
    "        batch_size=opt.batch_size, drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "else:\n",
    "    os.makedirs(\"../data/\" + args.dir_names + \"/\", exist_ok=True)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        opt.data,\n",
    "        batch_size=opt.batch_size, drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "print('done')\n",
    "\n",
    "data = iter(dataloader)\n",
    "x = data.next()\n",
    "input_size = x[0].shape[1] -3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################### load data for evaluation of model (not training set) and separate weights and target\n",
    "validation_data = opt.data.get_eval_data()\n",
    "\n",
    "w_val = validation_data[2]\n",
    "target_val = validation_data[1]\n",
    "target_val = Variable(torch.from_numpy(target_val).type(torch.LongTensor))\n",
    "y_val = validation_data[0]\n",
    "val_data = torch.reshape(y_val, (10 * y_val.shape[0], 4))\n",
    "                    \n",
    "# replace all negative weighted events with zero if the weight_cmd says to\n",
    "if opt.weight_cmd == \"no-neg\":\n",
    "    w_val[w_val < 0] = 0\n",
    "\n",
    "# remove weighting (aka, set all to 1) if weight_cmd says to\n",
    "if opt.weight_cmd == \"false\":\n",
    "    w_val = np.ones(w_val.shape)\n",
    "    \n",
    "w_val = Variable(torch.from_numpy(w_val).type(torch.FloatTensor))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_graphs = graph\n",
    "\n",
    "for i in range(y_val.shape[0] - 1):\n",
    "    val_graphs = dgl.batch([val_graphs, graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, 128)\n",
    "        self.conv2 = GraphConv(128, 64)\n",
    "        self.conv3 = GraphConv(64, 32)\n",
    "        self.conv4 = GraphConv(32, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = \n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv3(g,h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv4(g,h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()# this is the loss function. reduction='none' makes it return a value for each input (reduce=False was deprecated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GCN(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=20000, num_edges=72000,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = tensor(0.6763, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3b0c11ea38a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mbatched_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         batched_data = batched_data[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m#         print(\"prediction is \" + str(pred[0].dtype))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#         target = np.zeros((2,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cent7/5.1.0-py36/GANS_7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-aebaea5dde9c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, in_feat)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cent7/5.1.0-py36/GANS_7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cent7/5.1.0-py36/GANS_7/lib/python3.6/site-packages/dgl/nn/pytorch/conv/graphconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mshp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat_dst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m                 \u001b[0mrst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrst\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "\n",
    "small_loss = 1e20   # This is the initail loss under which we overwrite the model.\n",
    "                    # initialize with a large loss so everything is smaller than it\n",
    "\n",
    "# initialize loss arrays\n",
    "loss_val_array = np.array(())\n",
    "loss_array = np.array(())\n",
    "lva = 0  # this is the length of the loaded array\n",
    "la = 0  # this is the length of the other loaded array\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n",
    "loss_array = np.array(())\n",
    "validation_arry = np.array(())\n",
    "small_loss = 1e20   # This is the initail loss under which we overwrite the model.\n",
    "\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "    count = 0\n",
    "    for batched_data, labels, weights in dataloader:\n",
    "        count += count\n",
    "        init_batch = batched_data\n",
    "#         print(init_batch)\n",
    "#         print(batched_data.shape)\n",
    "        batched_data = torch.reshape(batched_data, (10 * opt.batch_size, 4))\n",
    "#         batched_data = batched_data[0]\n",
    "        pred = model(batched_graphs, batched_data)\n",
    "#         print(\"prediction is \" + str(pred[0].dtype))\n",
    "#         target = np.zeros((2,1))\n",
    "#         target[0] = 1-labels\n",
    "#         target[1] = labels\n",
    "#         labels = target.astype(int)\n",
    "#         labels = np.transpose(labels)\n",
    "\n",
    "#         labels = torch.from_numpy(labels)\n",
    "        labels = Variable(labels.type(torch.LongTensor))\n",
    "#         print(\"labels are \\n\" + str(labels))\n",
    "        loss = criterion(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#     if epoch % 5 == 0:\n",
    "# if count%1000 == 0:\n",
    "    #----------------------------------\n",
    "    # Draw training and validation loss\n",
    "    #-------------------------------------\n",
    "    print(\"loss = \" + str(loss))\n",
    "    if epoch %5 == 0:\n",
    "        loss_array = np.append(loss_array, loss.detach().numpy()) # append the training loss to the loss array\n",
    "        out = model(val_graphs, val_data)   # run classifier on validation data to see how good it is\n",
    "        loss_val = criterion(out, target_val)# calculate the validation loss\n",
    "        loss_val_array = np.append(loss_val_array, loss_val.detach().numpy()) # append the validation loss to its array\n",
    "\n",
    "\n",
    "        if small_loss > loss_val:   # compare to see if the loss has decreased\n",
    "            small_loss = loss_val   # if the network has improved replace the best loss with this one\n",
    "            torch.save(model.state_dict(), \"../models/GNN/\" + opt.model_name + \".pt\")   # save the new (and better) model\n",
    "            torch.save(optimizer.state_dict(), \"../models/GNN/optimizer_\" + opt.model_name + \".pt\") # save the optimizer state\n",
    "\n",
    "\n",
    "        np.save(\"../data/GNN/\" + opt.model_name +  \"_loss_val_array.npy\",loss_val_array)\n",
    "        np.save(\"../data/GNN/\" + opt.model_name + \"_loss_train_array.npy\",loss_array)\n",
    "        display.clear_output(True)\n",
    "        figure = plt.figure()\n",
    "        ax = figure.add_subplot(111)\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.plot(loss_val_array, label = \"evaluation loss\")\n",
    "        ax.plot(loss_array, label=\"training loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GANS)",
   "language": "python",
   "name": "gans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
