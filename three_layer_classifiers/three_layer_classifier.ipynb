{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "######################################### Import statements ###########################################\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")   # this allows us to import from sibling directory\n",
    "\n",
    "from code_to_import.dataset_preprocessing import ProductionModeDataset\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "#import torchvision.transforms as transforms\n",
    "#from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F   # NOTE: I don't think this is used\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l_eta', 'lbar_eta', 'l_phi', 'lbar_phi', 'l_pt', 'lbar_pt', 'l_mass', 'lbar_mass', 'b_eta', 'bbar_eta', 'b_phi', 'bbar_phi', 'b_pt', 'bbar_pt', 'b_mass', 'bbar_mass', 'llbar_delta_eta', 'bbbar_delta_eta', 'lbbar_delta_eta', 'blbar_delta_eta', 'lb_delta_eta', 'bbarlbar_delta_eta', 'llbar_delta_phi', 'bbbar_delta_phi', 'lbbar_delta_phi', 'blbar_delta_phi', 'lb_delta_phi', 'bbarlbar_delta_phi', 'production_mode', 'eventWeight', '__index__']\n",
      "num qqbar = 52908\n",
      "training (85710, 31)\n",
      "evaluating (20105, 31)\n",
      "The model in this run is testthreeLayerModel_ee_corrCut_-1_weights_true_drop_0.2_NoQG\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "######################## THIS CLASS INCLUDES ALL THE VARIABLES YOU WANT TO CONFIGURE #################################\n",
    "#######################################################################################################################\n",
    "\n",
    "class opt():   # Class used for optimizers in the future. Defines all variables and stuff needed.\n",
    "#     save_weights = True  # Tells whether to save weights... currently not used\n",
    "    \n",
    "    load_model = False  # set true if you want to load and continue training a previous model\n",
    "    \n",
    "    draw = True # set to false when running on slurm\n",
    "    \n",
    "    n_epochs = 40000   # an epoch is the number of times it works through the entire training set.\n",
    "                       # This sets the total number of epochs which will be run\n",
    "    \n",
    "    batch_size = 5000   # the training set is broken up into batches, \n",
    "                        # this sets the size of each batch\n",
    "    \n",
    "    weight_cmd = \"true\"   # could also be \"true\", \"false\" and \"no-neg\".\n",
    "                          # This determines whether weights and negative weights are used\n",
    "        \n",
    "    include_qg = False   # determines if qg events should be included\n",
    "        \n",
    "    drop = 0.2   # percentage of nodes which will be dropped each time\n",
    "    \n",
    "    lr = 0.0001   # learning rate (how much to change based on error)\n",
    "    b1 = 0.9   # Used for Adam. Exponential decay rate for the first moment\n",
    "    b2 = 0.999   # Used for Adam. Exponential decay rate for the second moment estimates (gradient squared)\n",
    "        \n",
    "    correlation_cut = -1  # this is the correlation cut... If negative then no cut is applied\n",
    "    \n",
    "    # the root_path leads to the folder with the root files being used for data\n",
    "    root_path = \"/depot/cms/top/mcnama20/TopSpinCorr-Run2-Entanglement/CMSSW_10_2_22/src/TopAnalysis/Configuration/analysis/diLeptonic/three_files/Nominal\"\n",
    "\n",
    "    file = root_path + \"/\" + \"ee\" + \"_modified_root_1_lorentzvectorsdelta.root\"   # this is the data root file loaded into the dataloader\n",
    "    \n",
    "    # this is the model name. Change it when running a new model\n",
    "    model_name = \"testthreeLayerModel_ee_corrCut_\" + str(correlation_cut)  + \"_weights_\" + weight_cmd + \"_drop_\" + str(drop)\n",
    "    \n",
    "    if not include_qg:\n",
    "        model_name += \"_NoQG\"\n",
    "    \n",
    "    # load data object so we can access validation and training data\n",
    "    \n",
    "    if correlation_cut > 0:\n",
    "        data = ProductionModeDataset(file, correlation_cut=correlation_cut, include_qgude_qg = include_qg)\n",
    "    else:\n",
    "        data = ProductionModeDataset(file, include_qg = include_qg)\n",
    "\n",
    "print(\"The model in this run is \" + opt.model_name)   # this will make slurm output easier to identify\n",
    "\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "############################## Configure data loader depending on if there is a correlation cut ###########################\n",
    "if opt.correlation_cut > 0:\n",
    "    os.makedirs(\"../data/three_layers/\", exist_ok=True)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        opt.data,\n",
    "        batch_size=opt.batch_size, drop_last=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "else:\n",
    "    os.makedirs(\"../data/three_layers/\", exist_ok=True)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        opt.data,\n",
    "        batch_size=opt.batch_size, drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "print('done')\n",
    "\n",
    "data = iter(dataloader)\n",
    "x = data.next()\n",
    "input_size = x.shape[1] -3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################### Now save training and validation sets for future analysis ###################################\n",
    "np.save(\"../data/three_layers/train_val_datasets/training_dataset_\" + opt.model_name + \".npy\", opt.data.get_training_data())\n",
    "np.save(\"../data/three_layers/train_val_datasets/validation_dataset_\" + opt.model_name + \".npy\", opt.data.get_eval_data())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    classifier layers\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()   # Just uses the module constructor with name Discriminator \n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),   # first layer\n",
    "            nn.BatchNorm1d(512),   # batch normalization\n",
    "            nn.Dropout(opt.drop),   # add dropout\n",
    "            nn.LeakyReLU(0.2, inplace=True),   # apply leaky relu to layer\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(opt.drop),   # add dropout\n",
    "            nn.BatchNorm1d(256),# batch normalization\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 2),\n",
    "            \n",
    "            # these are commented out because the last layer should have this happen\n",
    "#             nn.Dropout(drop),   # add dropout\n",
    "#             nn.BatchNorm1d(3),  # batch normalization\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        applies model to input and attempts to classify\n",
    "        \"\"\"\n",
    "        output = self.model(input)   # Classifies the input (at location) as gg (0) qqbar (1) or other (2)\n",
    "        return output\n",
    "\n",
    "\n",
    "# ******* OUT OF CLASSES NOW ************\n",
    "\n",
    "############### Initialize classifier and load a model if needed ##########################\n",
    "classifier = Classifier()\n",
    "if opt.load_model:\n",
    "    classifier.load_state_dict(torch.load(\"../models/three_layers/\" + opt.model_name + \".pt\")) #load module with same name\n",
    "    classifier.train()  # set the model up for training\n",
    "if cuda:\n",
    "    classifier.cuda()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################### load data for evaluation of model (not training set) and separate weights and target\n",
    "validation_data = opt.data.get_eval_data()\n",
    "\n",
    "w_val = validation_data[:,input_size + 1]\n",
    "\n",
    "target_val = validation_data[:,input_size]\n",
    "target_val = Variable(torch.from_numpy(target_val).type(torch.LongTensor))\n",
    "y_val = np.transpose(validation_data)\n",
    "y_val = np.delete(y_val, [input_size, input_size + 1, input_size + 2], 0)\n",
    "y_val = np.transpose(y_val)\n",
    "val_data = Variable(torch.from_numpy(y_val).type(torch.Tensor))\n",
    "\n",
    " # replace all negative weighted events with zero if the weight_cmd says to\n",
    "if opt.weight_cmd == \"no-neg\":\n",
    "    w_val[w_val < 0] = 0\n",
    "\n",
    "# remove weighting (aka, set all to 1) if weight_cmd says to\n",
    "if opt.weight_cmd == \"false\":\n",
    "    w_val = np.ones(w_val.shape)\n",
    "    \n",
    "w_val = Variable(torch.from_numpy(w_val).type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4002666\n",
      "0.40215808\n",
      "0.3990323\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-632763a8adb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mloss_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loss_l is a vector with the loss for each event in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# we take the dot product with the weights to calculate the final loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Do back propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Update parameters based on gradients for individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mbatches_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# increase the number of batches in the counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cent7/5.1.0-py36/GANS_7/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cent7/5.1.0-py36/GANS_7/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################### Initialize (and load if needed) optimizer and loss function ################################\n",
    "################################################################################################################\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2)) # set up optimizer\n",
    "if opt.load_model:\n",
    "    optimizer.load_state_dict(torch.load(\"../models/three_layers/optimizer_\" + opt.model_name + \".pt\"))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduce=False)# this is the loss function. reduce=false makes it return a value for each input\n",
    "\n",
    "##################################################################################################\n",
    "################ initialize stuff before training ################################################\n",
    "\n",
    "small_loss = 1e20   # This is the initail loss under which we overwrite the model.\n",
    "                    # initialize with a large loss so everything is smaller than it\n",
    "\n",
    "# initialize loss arrays\n",
    "loss_val_array = np.array(())\n",
    "loss_array = np.array(())\n",
    "lva = 0  # this is the length of the loaded array\n",
    "la = 0  # this is the length of the other loaded array\n",
    "\n",
    "# load arrays and reset small_loss if loading model:\n",
    "if opt.load_model:\n",
    "    loss_val_array = np.load(\"../data/three_layers/\" + opt.model_name +  \"_loss_val_array.npy\")\n",
    "    lva = len(loss_val_array)\n",
    "\n",
    "    loss_array = np.load(\"../data/three_layers/\" + opt.model_name +  \"_loss_train_array.npy\")\n",
    "    la = len(loss_array)\n",
    "    \n",
    "    small_loss = np.min(loss_val_array)\n",
    "    \n",
    "\n",
    "batches_done = 0   # Counter for batches\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "# ******************************** START TRAINING LOOP *******************************************************\n",
    "###############################################################################################################\n",
    "for epoch in range(opt.n_epochs):   # Loop through all epochs\n",
    "    for i, x in enumerate(dataloader): # x is a batch and there are i batches in the epoch\n",
    "        \n",
    "        #-----------------------------\n",
    "        # Configure input\n",
    "        #----------------------------\n",
    "        variable_len = len(x[0])\n",
    "        weight = x[:, variable_len-2]\n",
    "        weight = Variable(weight.type(torch.FloatTensor))\n",
    "        target = x[:, variable_len-3]\n",
    "        target = Variable(target.type(torch.LongTensor))\n",
    "        x = np.transpose(x)\n",
    "        x = np.delete(x, [variable_len-3, variable_len-2, variable_len-1], 0)\n",
    "        x = np.transpose(x)\n",
    "        batch = Variable(x.type(torch.Tensor))   # Variable is a wrapper for the Tensor x was just made into\n",
    "        \n",
    "        # replace all negative weighted events with zero if the weight_cmd says to\n",
    "        if opt.weight_cmd == \"no-neg\":\n",
    "            weight[weight < 0] = 0\n",
    "            #weight = Variable(torch.from_numpy(weight).type(torch.FloatTensor))\n",
    "        \n",
    "        # remove weighting (aka, set all to 1) if weight_cmd says to\n",
    "        if opt.weight_cmd == \"false\":\n",
    "            weight = np.ones(weight.shape)\n",
    "            weight = Variable(torch.from_numpy(weight).type(torch.FloatTensor))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Classifier\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer.zero_grad()   # Make gradients zero so they don't accumulate\n",
    "        \n",
    "        output = classifier(batch)   # apply nn to input   \n",
    "\n",
    "        # Calculate loss \n",
    "        loss_l = criterion(output, target) # loss_l is a vector with the loss for each event in the batch\n",
    "        loss = torch.dot(weight,loss_l)/(loss_l.shape[0])   # we take the dot product with the weights to calculate the final loss\n",
    "        loss.backward()   # Do back propagation \n",
    "        optimizer.step()   # Update parameters based on gradients for individuals\n",
    "        batches_done += 1  # increase the number of batches in the counter\n",
    "        \n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # Save and Draw Stuff  (if drawing is on)\n",
    "    #-----------------------------------------\n",
    "    if epoch % 10 == 0:\n",
    "        print(loss.detach().numpy())\n",
    "        loss_array = np.append(loss_array, loss.detach().numpy()) # append the training loss to the loss array\n",
    "        \n",
    "        \n",
    "        out = classifier(val_data)   # run classifier on validation data to see how good it is\n",
    "        loss_val = torch.dot(w_val, criterion(out, target_val))/(target_val.shape[0])   # calculate the validation loss\n",
    "        loss_val_array = np.append(loss_val_array, loss_val.detach().numpy()) # append the validation loss to its array\n",
    "        \n",
    "        if small_loss > loss_val:   # compare to see if the loss has decreased\n",
    "            small_loss = loss_val   # if the network has improved replace the best loss with this one\n",
    "            torch.save(classifier.state_dict(), \"../models/three_layers/\" + opt.model_name + \".pt\")   # save the new (and better) model\n",
    "            torch.save(optimizer.state_dict(), \"../models/three_layers/optimizer_\" + opt.model_name + \".pt\") # save the optimizer state\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            # save the loss arrays\n",
    "            np.save(\"../data/three_layers/\" + opt.model_name +  \"_loss_val_array.npy\",loss_val_array)\n",
    "            np.save(\"../data/three_layers/\" + opt.model_name + \"_loss_train_array.npy\",loss_array)\n",
    "            if opt.draw:\n",
    "                #----------------------------------\n",
    "                # Draw training and validation loss\n",
    "                #-------------------------------------\n",
    "                display.clear_output(True)\n",
    "                figure = plt.figure()\n",
    "                ax = figure.add_subplot(111)\n",
    "                #ax.set_yscale(\"log\")\n",
    "                ax.plot(10 * np.array(list(range(int((epoch)/10)+lva+1))), loss_array, label=\"training loss\")\n",
    "                ax.plot(10 * np.array(list(range(int((epoch)/10)+la+1))), loss_val_array, label = \"evaluation loss\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env: GANS_7]",
   "language": "python",
   "name": "conda-env-GANS_7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
